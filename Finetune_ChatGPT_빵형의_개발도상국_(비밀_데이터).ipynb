{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leo2park/PyTorch/blob/master/Finetune_ChatGPT_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD_(%EB%B9%84%EB%B0%80_%EB%8D%B0%EC%9D%B4%ED%84%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT(GPT-3.5) 파인튜닝\n",
        "\n",
        "> 유튜브 [빵형의 개발도상국](https://www.youtube.com/@bbanghyong)\n",
        "\n",
        "- 참고문서: https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model\n",
        "- 가격: https://openai.com/pricing"
      ],
      "metadata": {
        "id": "4mVY-Zs4A56w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai tqdm gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCu3AkXm4fCp",
        "outputId": "c71a20c2-0a38-4624-a57b-c37c2d481a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess custom dataset"
      ],
      "metadata": {
        "id": "T-IvaP1gBHw1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCQOf-0s3sEv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/KakaoTalk_Chat.csv\")\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rBW6eUCO3_Z0",
        "outputId": "9d609201-7694-44a6-e274-0b0d10cab2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Date           User  \\\n",
              "0      2023-01-12 22:16:57     원종윤 교수 동명대   \n",
              "1      2023-01-12 22:16:56     원종윤 교수 동명대   \n",
              "2      2023-01-12 22:17:01     원종윤 교수 동명대   \n",
              "3      2023-01-12 22:17:12     원종윤 교수 동명대   \n",
              "4      2023-01-12 22:25:07       이태희 (빵형)   \n",
              "...                    ...            ...   \n",
              "10214  2023-08-23 09:48:10  유용균 박사 원자력연구원   \n",
              "10215  2023-08-23 09:48:15  유용균 박사 원자력연구원   \n",
              "10216  2023-08-23 09:48:22  유용균 박사 원자력연구원   \n",
              "10217  2023-08-23 09:48:27  유용균 박사 원자력연구원   \n",
              "10218  2023-08-23 09:48:30  유용균 박사 원자력연구원   \n",
              "\n",
              "                                                 Message  \n",
              "0        원종윤 교수 동명대님이 이태희 (빵형)님과 유용균 박사 원자력연구원님을 초대했습니다.  \n",
              "1      피곤하시겠지만,., 써놓은김에 보내드립니다..('' )\\n\\n[한국색채연구소 과제만...  \n",
              "2             파일: 연구개발계획서 본문1_(주)한국색채디자인개발원_S3205489.pdf  \n",
              "3                                이건 이번에 파생하는 용역의 모 과제..   \n",
              "4                                          오오 이사업 흥미롭네요!  \n",
              "...                                                  ...  \n",
              "10214                                        파인튜닝의 부작용으로  \n",
              "10215                                       흑역사가 툭 튀어나오면  \n",
              "10216                                              ㅋㅋㅋㅋㅋ  \n",
              "10217                                   아 어짜피 라이브방송은 아니니  \n",
              "10218                                         상관없겠구나 ㅋㅋㅋ  \n",
              "\n",
              "[10219 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a80e79d8-7867-44b9-a1d6-97991db100be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>User</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-01-12 22:16:57</td>\n",
              "      <td>원종윤 교수 동명대</td>\n",
              "      <td>원종윤 교수 동명대님이 이태희 (빵형)님과 유용균 박사 원자력연구원님을 초대했습니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-01-12 22:16:56</td>\n",
              "      <td>원종윤 교수 동명대</td>\n",
              "      <td>피곤하시겠지만,., 써놓은김에 보내드립니다..('' )\\n\\n[한국색채연구소 과제만...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-01-12 22:17:01</td>\n",
              "      <td>원종윤 교수 동명대</td>\n",
              "      <td>파일: 연구개발계획서 본문1_(주)한국색채디자인개발원_S3205489.pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-01-12 22:17:12</td>\n",
              "      <td>원종윤 교수 동명대</td>\n",
              "      <td>이건 이번에 파생하는 용역의 모 과제..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-01-12 22:25:07</td>\n",
              "      <td>이태희 (빵형)</td>\n",
              "      <td>오오 이사업 흥미롭네요!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10214</th>\n",
              "      <td>2023-08-23 09:48:10</td>\n",
              "      <td>유용균 박사 원자력연구원</td>\n",
              "      <td>파인튜닝의 부작용으로</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10215</th>\n",
              "      <td>2023-08-23 09:48:15</td>\n",
              "      <td>유용균 박사 원자력연구원</td>\n",
              "      <td>흑역사가 툭 튀어나오면</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10216</th>\n",
              "      <td>2023-08-23 09:48:22</td>\n",
              "      <td>유용균 박사 원자력연구원</td>\n",
              "      <td>ㅋㅋㅋㅋㅋ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10217</th>\n",
              "      <td>2023-08-23 09:48:27</td>\n",
              "      <td>유용균 박사 원자력연구원</td>\n",
              "      <td>아 어짜피 라이브방송은 아니니</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10218</th>\n",
              "      <td>2023-08-23 09:48:30</td>\n",
              "      <td>유용균 박사 원자력연구원</td>\n",
              "      <td>상관없겠구나 ㅋㅋㅋ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10219 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a80e79d8-7867-44b9-a1d6-97991db100be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a80e79d8-7867-44b9-a1d6-97991db100be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a80e79d8-7867-44b9-a1d6-97991db100be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb5d742c-fa12-499e-8f05-6c11a1ffb71b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb5d742c-fa12-499e-8f05-6c11a1ffb71b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb5d742c-fa12-499e-8f05-6c11a1ffb71b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format\n",
        "\n",
        "```json\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
        "```"
      ],
      "metadata": {
        "id": "o1JGBNEC4xbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- n, n+1 쌍으로 제작\n",
        "- 이렇게 하면 같은 사람 데이터가 섞일 가능성이 높아서 실제로 챗봇을 만들때에는 데이터 전처리가 중요"
      ],
      "metadata": {
        "id": "OWTeW_AoDfro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "\n",
        "for i, row in tqdm(df.iterrows()):\n",
        "    try:\n",
        "        message = {\"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"ChatSNS is a chatbot really friendly and concise.\"},\n",
        "            {\"role\": \"user\", \"content\": df.iloc[i][\"Message\"]},\n",
        "            {\"role\": \"assistant\", \"content\": df.iloc[i+1][\"Message\"]}\n",
        "        ]}\n",
        "        messages.append(message)\n",
        "    except:\n",
        "        break\n",
        "\n",
        "messages[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_WbBrQf4CuU",
        "outputId": "b050e760-7456-4fc0-87f2-128255660fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10218it [00:01, 7848.34it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'messages': [{'role': 'system',\n",
              "    'content': 'ChatSNS is a chatbot really friendly and concise.'},\n",
              "   {'role': 'user', 'content': 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ'},\n",
              "   {'role': 'assistant', 'content': '파인튜닝의 부작용으로'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'ChatSNS is a chatbot really friendly and concise.'},\n",
              "   {'role': 'user', 'content': '파인튜닝의 부작용으로'},\n",
              "   {'role': 'assistant', 'content': '흑역사가 툭 튀어나오면'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'ChatSNS is a chatbot really friendly and concise.'},\n",
              "   {'role': 'user', 'content': '흑역사가 툭 튀어나오면'},\n",
              "   {'role': 'assistant', 'content': 'ㅋㅋㅋㅋㅋ'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'ChatSNS is a chatbot really friendly and concise.'},\n",
              "   {'role': 'user', 'content': 'ㅋㅋㅋㅋㅋ'},\n",
              "   {'role': 'assistant', 'content': '아 어짜피 라이브방송은 아니니'}]},\n",
              " {'messages': [{'role': 'system',\n",
              "    'content': 'ChatSNS is a chatbot really friendly and concise.'},\n",
              "   {'role': 'user', 'content': '아 어짜피 라이브방송은 아니니'},\n",
              "   {'role': 'assistant', 'content': '상관없겠구나 ㅋㅋㅋ'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"messages.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for entry in messages:\n",
        "        json.dump(entry, f, ensure_ascii=False)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "qD0LRsrS4MK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload the file to OpenAI server"
      ],
      "metadata": {
        "id": "5UEfp119BNhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "openai.File.create(\n",
        "    file=open(\"messages.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DhXPAPI6onT",
        "outputId": "1c153bd3-0a98-4768-d415-306c201401a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-r3O7kr2EmFn9Rtw6sqSlrorI at 0x7c51efebed90> JSON: {\n",
              "  \"object\": \"file\",\n",
              "  \"id\": \"file-r3O7kr2EmFn9Rtw6sqSlrorI\",\n",
              "  \"purpose\": \"fine-tune\",\n",
              "  \"filename\": \"file\",\n",
              "  \"bytes\": 2646889,\n",
              "  \"created_at\": 1692752975,\n",
              "  \"status\": \"uploaded\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune\n",
        "\n",
        "- 업로드 후 5분 정도 기다려야 파인튜닝 시작할 수 있음\n",
        "- (아마 사용자가 몰리면 오래 걸리는 듯)"
      ],
      "metadata": {
        "id": "0BOGYK4l9dIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = \"file-r3O7kr2EmFn9Rtw6sqSlrorI\"\n",
        "\n",
        "openai.FineTuningJob.create(\n",
        "    training_file=id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGs14-b18JA6",
        "outputId": "3ba019a2-2c6b-4e4e-fddf-52a19ad43315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-pr3bBLwkpi3N2zKAcu3nUk6I at 0x7c51bc33c400> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-pr3bBLwkpi3N2zKAcu3nUk6I\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1692753306,\n",
              "  \"finished_at\": null,\n",
              "  \"fine_tuned_model\": null,\n",
              "  \"organization_id\": \"org-QXOk83jF1b5SHs7BAOHw7Jed\",\n",
              "  \"result_files\": [],\n",
              "  \"status\": \"created\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-r3O7kr2EmFn9Rtw6sqSlrorI\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 2\n",
              "  },\n",
              "  \"trained_tokens\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파인튜닝 진행상황 확인\n",
        "\n",
        "- 10:15 시작\n",
        "- 10:55 끝\n",
        "- 1,337,788 토큰\n",
        "- 약 40분 소요 (2 Epoch)"
      ],
      "metadata": {
        "id": "tPX8L1wfBZ9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.list(limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsqLVR6p8c-e",
        "outputId": "320659fc-41b1-48ec-86e2-c8332de48b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7c51bacef600> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-pr3bBLwkpi3N2zKAcu3nUk6I\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1692753306,\n",
              "      \"finished_at\": 1692755783,\n",
              "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7qXOWj87\",\n",
              "      \"organization_id\": \"org-QXOk83jF1b5SHs7BAOHw7Jed\",\n",
              "      \"result_files\": [\n",
              "        \"file-Vrj3qR9oduT1NziH3Ie3QL5W\"\n",
              "      ],\n",
              "      \"status\": \"succeeded\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-r3O7kr2EmFn9Rtw6sqSlrorI\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 2\n",
              "      },\n",
              "      \"trained_tokens\": 1337788\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "izXQaYz9Bsrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"ft:gpt-3.5-turbo-0613:personal::7qXOWj87\"\n",
        "\n",
        "user_input = \"오늘 뭐하세요?\"\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=model_id,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"ChatSNS is a chatbot really friendly and concise.\"},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SejDj389QkW",
        "outputId": "f204376e-1074-40d2-9a29-5db0d727d28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "해외 전통문화관 과제 1차 평가 모임 날짜 지정 같네요.. \n",
            "우리 서울시 지원 행사죠. 대표 참석하시고 서울시점 추가공약해서    \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio Chatbot"
      ],
      "metadata": {
        "id": "TOYKGGUjBuPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict(input, history):\n",
        "    history.append({\"role\": \"user\", \"content\": input})\n",
        "\n",
        "    gpt_response = openai.ChatCompletion.create(\n",
        "        model=model_id,\n",
        "        messages=history\n",
        "    )\n",
        "\n",
        "    response = gpt_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    messages = [(history[i][\"content\"], history[i+1][\"content\"]) for i in range(1, len(history), 2)]\n",
        "\n",
        "    return messages, history\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(label=\"ChatBot\")\n",
        "\n",
        "    state = gr.State([{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"ChatSNS is a chatbot really friendly and concise.\"\n",
        "    }])\n",
        "\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(show_label=False, placeholder=\"챗봇에게 아무거나 물어보세요\").style(container=False)\n",
        "\n",
        "    txt.submit(predict, [txt, state], [chatbot, state])\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "zzHnjFdT9kMI",
        "outputId": "007af457-a37f-41c6-ada4-f28e2fddde46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-3d05a31f0091>:29: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  txt = gr.Textbox(show_label=False, placeholder=\"챗봇에게 아무거나 물어보세요\").style(container=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://a17b3cd80c3d25dd86.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a17b3cd80c3d25dd86.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a17b3cd80c3d25dd86.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}