{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leo2park/PyTorch/blob/master/Finetune_ChatGPT_(20%EB%8C%80_%EC%97%AC%EC%84%B1_%EC%B1%97%EB%B4%87_%EB%A7%8C%EB%93%A4%EA%B8%B0)_%EB%B9%B5%ED%98%95%EC%9D%98_%EA%B0%9C%EB%B0%9C%EB%8F%84%EC%83%81%EA%B5%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT(GPT-3.5) 파인튜닝\n",
        "\n",
        "> 유튜브 [빵형의 개발도상국](https://www.youtube.com/@bbanghyong)\n",
        "\n",
        "- 참고문서: https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model\n",
        "- 가격: https://openai.com/pricing"
      ],
      "metadata": {
        "id": "4mVY-Zs4A56w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai tqdm gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCu3AkXm4fCp",
        "outputId": "170055d9-b52f-4b34-b3bf-2e726aff7e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess custom dataset\n",
        "\n",
        "- [주제별 텍스트 일상 대화 데이터](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=543)\n",
        "- [한국어 SNS](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=114)\n",
        "\n",
        "> \"주제별 텍스트 일상 대화 데이터\" 샘플 데이터셋에서 20대 여성 데이터만 추출\n",
        "\n",
        "- 4,532쌍의 대화 데이터셋\n",
        "\n",
        "### 전처리 코드\n",
        "\n",
        "```\n",
        "{'id': '1번', 'sex': '여성', 'age': '20대'}: 홀랭 키키\n",
        "{'id': '2번', 'sex': '여성', 'age': '20대'}: 거기에 웃긴 썰이 나올 수 있는 거야?\n",
        "{'id': '1번', 'sex': '여성', 'age': '20대'}: 어 있으 키키\n",
        "{'id': '2번', 'sex': '여성', 'age': '20대'}: 그냥 시원한 거 같기도 하고 키키\n",
        "{'id': '2번', 'sex': '여성', 'age': '20대'}: 아 그날이 제일 긴장되는 날이긴 하지...\n",
        "{'id': '1번', 'sex': '여성', 'age': '20대'}: 어 맞아,\n",
        "{'id': '2번', 'sex': '여성', 'age': '20대'}: 음 한 100만 원은 나오지 않았을까?\n",
        "{'id': '1번', 'sex': '여성', 'age': '20대'}: 거의 맞췄어,\n",
        "{'id': '2번', 'sex': '여성', 'age': '20대'}: 뭐야\n",
        "{'id': '1번', 'sex': '여성', 'age': '20대'}: 키키 나도 소름 돋았어\n",
        "```\n",
        "\n",
        "```python\n",
        "from glob import glob\n",
        "import json\n",
        "\n",
        "txt_list = sorted(glob(\"라벨링데이터/TL_02. FACEBOOK/*.json\"))\n",
        "\n",
        "is_break = False\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "messages = []\n",
        "\n",
        "for txt_path in txt_list:\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    prev_speaker_id = None\n",
        "    prev_text = \"\"\n",
        "\n",
        "    lines = data[\"info\"][0][\"annotations\"][\"lines\"]\n",
        "    i = 0\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            line = lines[i]\n",
        "        except:\n",
        "            break\n",
        "\n",
        "        speaker_id = line[\"speaker\"][\"id\"]\n",
        "\n",
        "        if prev_text and prev_speaker_id is not None and speaker_id != prev_speaker_id:\n",
        "            try:\n",
        "                message = {\"messages\": [\n",
        "                    {\"role\": \"system\", \"content\": \"You are a friendly woman in your twenties.\"},\n",
        "                    {\"role\": \"user\", \"content\": prev_text.strip()},\n",
        "                    {\"role\": \"assistant\", \"content\": line[\"norm_text\"]}\n",
        "                ]}\n",
        "                messages.append(message)\n",
        "\n",
        "                print(f\"{line['speaker']}: {line['norm_text']}\")\n",
        "\n",
        "                prev_text = \"\"\n",
        "            except:\n",
        "                break\n",
        "        else:\n",
        "            prev_text += line[\"norm_text\"] + \"\\n\"\n",
        "            i += 1\n",
        "\n",
        "        prev_speaker_id = speaker_id\n",
        "\n",
        "    if is_break:\n",
        "        break\n",
        "\n",
        "    cnt += 1\n",
        "\n",
        "with open(\"messages.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for entry in messages:\n",
        "        json.dump(entry, f, ensure_ascii=False)\n",
        "        f.write('\\n')\n",
        "\n",
        "print(cnt)\n",
        "```"
      ],
      "metadata": {
        "id": "T-IvaP1gBHw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/kairess/toy-datasets/raw/master/messages_20%E1%84%83%E1%85%A2%E1%84%8B%E1%85%A7%E1%84%89%E1%85%A5%E1%86%BC.jsonl -O messages.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4EmbR98hRpX",
        "outputId": "c82602ca-b0aa-48c0-d45c-4bdb3095fe44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-23 12:56:30--  https://github.com/kairess/toy-datasets/raw/master/messages_20%E1%84%83%E1%85%A2%E1%84%8B%E1%85%A7%E1%84%89%E1%85%A5%E1%86%BC.jsonl\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kairess/toy-datasets/master/messages_20%E1%84%83%E1%85%A2%E1%84%8B%E1%85%A7%E1%84%89%E1%85%A5%E1%86%BC.jsonl [following]\n",
            "--2023-08-23 12:56:30--  https://raw.githubusercontent.com/kairess/toy-datasets/master/messages_20%E1%84%83%E1%85%A2%E1%84%8B%E1%85%A7%E1%84%89%E1%85%A5%E1%86%BC.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1173433 (1.1M) [text/plain]\n",
            "Saving to: ‘messages.jsonl’\n",
            "\n",
            "messages.jsonl      100%[===================>]   1.12M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-08-23 12:56:31 (16.9 MB/s) - ‘messages.jsonl’ saved [1173433/1173433]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format\n",
        "\n",
        "```json\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
        "```"
      ],
      "metadata": {
        "id": "o1JGBNEC4xbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"messages.jsonl\", lines=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "KRH1uQCEhXfv",
        "outputId": "a2730bd6-bee4-401d-c0fd-e2ef3c271e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            messages\n",
              "0  [{'role': 'system', 'content': 'You are a frie...\n",
              "1  [{'role': 'system', 'content': 'You are a frie...\n",
              "2  [{'role': 'system', 'content': 'You are a frie...\n",
              "3  [{'role': 'system', 'content': 'You are a frie...\n",
              "4  [{'role': 'system', 'content': 'You are a frie..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-306f689b-3741-4e71-802c-e46bb777809c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>messages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a frie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-306f689b-3741-4e71-802c-e46bb777809c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-306f689b-3741-4e71-802c-e46bb777809c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-306f689b-3741-4e71-802c-e46bb777809c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75b02340-dc3c-46a0-ac96-7157b364fdd3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75b02340-dc3c-46a0-ac96-7157b364fdd3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75b02340-dc3c-46a0-ac96-7157b364fdd3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload the file to OpenAI server"
      ],
      "metadata": {
        "id": "5UEfp119BNhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "openai.File.create(\n",
        "    file=open(\"messages.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DhXPAPI6onT",
        "outputId": "968e194a-c706-49a0-fc2d-28e0d0699036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-bgsFeM8i0XGDPz0rxjZMRbTd at 0x780872f52520> JSON: {\n",
              "  \"object\": \"file\",\n",
              "  \"id\": \"file-bgsFeM8i0XGDPz0rxjZMRbTd\",\n",
              "  \"purpose\": \"fine-tune\",\n",
              "  \"filename\": \"file\",\n",
              "  \"bytes\": 1173433,\n",
              "  \"created_at\": 1692762905,\n",
              "  \"status\": \"uploaded\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune\n",
        "\n",
        "- 위의 id를 복사해서 붙여넣기\n",
        "- 업로드 후 5분 정도 기다려야 파인튜닝 시작할 수 있음\n",
        "- (아마 사용자가 몰리면 오래 걸리는 듯)"
      ],
      "metadata": {
        "id": "0BOGYK4l9dIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = \"file-bgsFeM8i0XGDPz0rxjZMRbTd\"\n",
        "\n",
        "openai.FineTuningJob.create(\n",
        "    training_file=id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGs14-b18JA6",
        "outputId": "20237afa-19e2-4579-ce10-5b051d291e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-Suhw8DZSTk2bawxjQ1UoaW08 at 0x780872f1f010> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-Suhw8DZSTk2bawxjQ1UoaW08\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1692763020,\n",
              "  \"finished_at\": null,\n",
              "  \"fine_tuned_model\": null,\n",
              "  \"organization_id\": \"org-QXOk83jF1b5SHs7BAOHw7Jed\",\n",
              "  \"result_files\": [],\n",
              "  \"status\": \"created\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-bgsFeM8i0XGDPz0rxjZMRbTd\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파인튜닝 진행상황 확인\n",
        "\n",
        "- 12:57 시작\n",
        "- 13:35 끝\n",
        "- 4,532쌍의 대화 데이터\n",
        "- 894,228 토큰 (약 7USD 청구)\n",
        "- 약 40분 소요 (3 Epoch)\n",
        "- Epoch을 결정하는 기준을 모르겠음. 설정값이 있는지 확인 필요."
      ],
      "metadata": {
        "id": "tPX8L1wfBZ9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.list(limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsqLVR6p8c-e",
        "outputId": "f96d528d-fe6c-45b3-a8f8-c1afcb986317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x780871b59530> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-Suhw8DZSTk2bawxjQ1UoaW08\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1692763020,\n",
              "      \"finished_at\": 1692765323,\n",
              "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7qZsPxh8\",\n",
              "      \"organization_id\": \"org-QXOk83jF1b5SHs7BAOHw7Jed\",\n",
              "      \"result_files\": [\n",
              "        \"file-V9bEVcg9vUnVH7HZYLpJI5gN\"\n",
              "      ],\n",
              "      \"status\": \"succeeded\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-bgsFeM8i0XGDPz0rxjZMRbTd\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 3\n",
              "      },\n",
              "      \"trained_tokens\": 894228\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-pr3bBLwkpi3N2zKAcu3nUk6I\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1692753306,\n",
              "      \"finished_at\": 1692755783,\n",
              "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7qXOWj87\",\n",
              "      \"organization_id\": \"org-QXOk83jF1b5SHs7BAOHw7Jed\",\n",
              "      \"result_files\": [\n",
              "        \"file-Vrj3qR9oduT1NziH3Ie3QL5W\"\n",
              "      ],\n",
              "      \"status\": \"succeeded\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-r3O7kr2EmFn9Rtw6sqSlrorI\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 2\n",
              "      },\n",
              "      \"trained_tokens\": 1337788\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test\n",
        "\n",
        "- 완료되면 `data - fine_tuned_model`에 `ft:gpt-3.5-turbo-0613:xxxxx::xxxxx` 이런식으로 커스텀 모델 id 부여됨.\n",
        "- 파인튜닝한 모델은 만든 사람 또는 권한이 있는 사람만 사용할 수 있음."
      ],
      "metadata": {
        "id": "izXQaYz9Bsrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"ft:gpt-3.5-turbo-0613:personal::7qZsPxh8\"\n",
        "\n",
        "user_input = \"뭐해 키키\"\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "    model=model_id,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a friendly woman in your twenties.\"},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SejDj389QkW",
        "outputId": "5327c17f-5849-49af-88d2-65ea40e73012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나 지금 남친이랑 돈 써서 게임 돌리는 중!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio Chatbot"
      ],
      "metadata": {
        "id": "TOYKGGUjBuPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict(input, history):\n",
        "    history.append({\"role\": \"user\", \"content\": input})\n",
        "\n",
        "    gpt_response = openai.ChatCompletion.create(\n",
        "        model=model_id,\n",
        "        messages=history\n",
        "    )\n",
        "\n",
        "    response = gpt_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    messages = [(history[i][\"content\"], history[i+1][\"content\"]) for i in range(1, len(history), 2)]\n",
        "\n",
        "    return messages, history\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot(label=\"ChatBot\")\n",
        "\n",
        "    state = gr.State([{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"ChatSNS is a chatbot really friendly and concise.\"\n",
        "    }])\n",
        "\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(show_label=False, placeholder=\"챗봇에게 아무거나 물어보세요\").style(container=False)\n",
        "\n",
        "    txt.submit(predict, [txt, state], [chatbot, state])\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzHnjFdT9kMI",
        "outputId": "0d9fd7b7-43c0-40b6-d3d1-0a5a8f40c2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9af5dd5558a7a0cb43.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}